{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Most Simple Neural Network\n",
    "\n",
    "I'm not going to try and explain this in any detail, I just threw this in to show you that a neural network is just a fancy name for layers of big matrix multiplications... That's all!\n",
    "\n",
    "Our toy dataset is just sets of three 1's and 0's, but these actually represent traffic light colors and the label (again a 1 or a 0) represents *stop* or *go*.\n",
    "\n",
    "Run the cell and you should see the model slowly learn an association between the dataset as input, and the target classification as output.. THAT'S COOL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h65mpuU0S-mL",
    "outputId": "5ac513f2-e317-4a22-f44d-007052571872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9688563298232127\n",
      "1.3969131563706096\n",
      "0.9983029894702801\n",
      "0.7156526900082276\n",
      "0.5127262189032928\n",
      "0.36581073750913595\n",
      "0.25892932321832923\n",
      "0.1810540750425636\n",
      "0.12441865952704236\n",
      "0.08346145396707895\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Our Dataset\n",
    "data = np.array([[0, 0, 1],\n",
    "                 [0, 1, 0],\n",
    "                 [1, 0, 0],\n",
    "                 [1, 1, 0]])\n",
    "# Dataset Labels\n",
    "targets = np.array([1, 0, 0, 1])\n",
    "\n",
    "hidden_size = 4\n",
    "alpha = 0.01\n",
    "iterations = 10\n",
    "\n",
    "# Hidden Layers\n",
    "weights_0 = np.random.random((data[0].size, hidden_size))\n",
    "weights_1 = np.random.random((hidden_size, 1))\n",
    "\n",
    "# Activation Function\n",
    "def relu(x): return (x > 0) * x\n",
    "# Derivative of Activation Function\n",
    "def relu_deriv(x): return (x > 0)\n",
    "\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    total_error = 0\n",
    "    for i in range(len(data)):\n",
    "        inp = data[i:i+1]\n",
    "        target = targets[i:i+1]\n",
    "\n",
    "        # Forward Pass\n",
    "        layer_1 = relu(inp.dot(weights_0))\n",
    "        layer_2 = layer_1.dot(weights_1)\n",
    "\n",
    "        # Error\n",
    "        layer_2_delta = layer_2 - target\n",
    "        total_error = np.sum(layer_2_delta ** 2)\n",
    "\n",
    "        # Backpropagation\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1.T) * relu_deriv(layer_1)\n",
    "        weights_1 -= alpha * (layer_1.T.dot(layer_2_delta)) # Update Weights Layer 1\n",
    "        weights_0 -= alpha * (inp.T.dot(layer_1_delta))     # Update Weights Layer 0\n",
    "\n",
    "    # Our error should decrease as the model trains...\n",
    "    print(total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OroBqbQdS_nd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "the_most_simple_neural_network_ever.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
